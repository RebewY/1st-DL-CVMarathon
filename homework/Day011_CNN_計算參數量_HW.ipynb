{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f6jN0Y8x4gNA"
   },
   "source": [
    "## 『本次練習內容』\n",
    "#### 運用Keras搭建簡單的Dense Layer與 Convolution2D Layer，使用相同Neurons數量，計算總參數量相差多少。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 本次練習主要是要讓各位同學們了解CNN與FC層的參數使用量差異\n",
    "  #### Convolution2D有許多參數可以設置，之後章節會細談\n",
    "  #### 不熟Keras的學員們也可以藉此了解NN層的不同搭法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SAFr7hM24gNB"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 3)         30        \n",
      "=================================================================\n",
      "Total params: 30\n",
      "Trainable params: 30\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 288)               226080    \n",
      "=================================================================\n",
      "Total params: 226,080\n",
      "Trainable params: 226,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "##輸入照片尺寸==28*28*1\n",
    "##都用一層，288個神經元\n",
    "\n",
    "##建造一個一層的CNN層\n",
    "classifier=Sequential()\n",
    "##Kernel size 3*3，用32張，輸入大小28*28*1\n",
    "classifier.add(Convolution2D(kernel_size=3,filters=3,padding='same',input_shape=(28,28,1)))#'''32張Kernel，大小為3*3，輸入尺寸為28*28*1'''\n",
    "##看看model結構\n",
    "print(classifier.summary())\n",
    "#'''理解輸出Total params為何==320'''\n",
    "\n",
    "##建造一個一層的FC層\n",
    "classifier=Sequential()\n",
    "##輸入為28*28*1攤平==784\n",
    "inputs = Input(shape=(784,))#'''輸入尺寸為28*28*1'''\n",
    "##CNN中用了(3*3*1)*32個神經元，我們這邊也用相同神經元數量\n",
    "x=Dense(288,activation='relu')(inputs)#'''使用288個神經元'''\n",
    "model = Model(inputs=inputs, outputs=x)\n",
    "##看看model結構\n",
    "print(model.summary())\n",
    "#'''理解輸出Total params為何==226080'''\n",
    "\n",
    "##大家可以自己變換設定看看參數變化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 4s 0us/step\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.2454 - accuracy: 0.9248 - val_loss: 0.1096 - val_accuracy: 0.9677\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.1025 - accuracy: 0.9691 - val_loss: 0.0814 - val_accuracy: 0.9759\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.0764 - accuracy: 0.9772 - val_loss: 0.0798 - val_accuracy: 0.9768\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.0592 - accuracy: 0.9823 - val_loss: 0.0805 - val_accuracy: 0.9794\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.0509 - accuracy: 0.9848 - val_loss: 0.0800 - val_accuracy: 0.9811\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.0462 - accuracy: 0.9860 - val_loss: 0.0778 - val_accuracy: 0.9789\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 8s 125us/step - loss: 0.0375 - accuracy: 0.9884 - val_loss: 0.0968 - val_accuracy: 0.9779\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.0328 - accuracy: 0.9902 - val_loss: 0.0902 - val_accuracy: 0.9826\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.0318 - accuracy: 0.9908 - val_loss: 0.0924 - val_accuracy: 0.9824\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.0268 - accuracy: 0.9917 - val_loss: 0.0910 - val_accuracy: 0.9826\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0251 - accuracy: 0.9928 - val_loss: 0.1060 - val_accuracy: 0.9806\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 8s 133us/step - loss: 0.0247 - accuracy: 0.9931 - val_loss: 0.0888 - val_accuracy: 0.9836\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.0244 - accuracy: 0.9933 - val_loss: 0.1033 - val_accuracy: 0.9836\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.0228 - accuracy: 0.9940 - val_loss: 0.1053 - val_accuracy: 0.9842\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 8s 133us/step - loss: 0.0207 - accuracy: 0.9941 - val_loss: 0.1014 - val_accuracy: 0.9840\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.0211 - accuracy: 0.9938 - val_loss: 0.1201 - val_accuracy: 0.9830\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.0193 - accuracy: 0.9948 - val_loss: 0.1117 - val_accuracy: 0.9835\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.0165 - accuracy: 0.9954 - val_loss: 0.1175 - val_accuracy: 0.9851\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 0.0188 - accuracy: 0.9954 - val_loss: 0.1304 - val_accuracy: 0.9840\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 9s 142us/step - loss: 0.0198 - accuracy: 0.9949 - val_loss: 0.1211 - val_accuracy: 0.9823\n",
      "Test loss: 0.12105275678167211\n",
      "Test accuracy: 0.9822999835014343\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple deep NN on the MNIST dataset.\n",
    "\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning).\n",
    "2 seconds per epoch on a K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "CNN-計算參數量.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
